<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on Oleg Baydakov</title>
    <link>https://obaydakov.github.io/categories/spark/</link>
    <description>Recent content in Spark on Oleg Baydakov</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 12 May 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://obaydakov.github.io/categories/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A library for reading data from Akka Actors using Spark Streaming.</title>
      <link>https://obaydakov.github.io/post/2018/a-library-for-reading-data-from-akka-actors-using-spark-streaming/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/a-library-for-reading-data-from-akka-actors-using-spark-streaming/</guid>
      <description>Link
Apache Bahir Extensions for Apache Spark Downloads</description>
    </item>
    
    <item>
      <title>How to connect Akka Stream and Spark Streaming by turning creating a Flow element that feeds into an InputDstream</title>
      <link>https://obaydakov.github.io/post/2018/how-to-connect-akka-stream-and-spark-streaming/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/how-to-connect-akka-stream-and-spark-streaming/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Self-contained examples of Apache Spark streaming integrated with Apache Kafka.</title>
      <link>https://obaydakov.github.io/post/2018/self-contained-examples-of-apache-spark-streaming-integrated-with-apache-kafka/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/self-contained-examples-of-apache-spark-streaming-integrated-with-apache-kafka/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Structured Streaming in Apache Spark 2.2&#43; GitBook </title>
      <link>https://obaydakov.github.io/post/2018/structured-streaming-in-apache-spark-2-2-gitbook/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/structured-streaming-in-apache-spark-2-2-gitbook/</guid>
      <description>Link
E-book</description>
    </item>
    
    <item>
      <title>Using Spark SQL and Spark Streaming together</title>
      <link>https://obaydakov.github.io/post/2018/using-spark-sql-and-spark-streaming-together/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/using-spark-sql-and-spark-streaming-together/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>MMLSpark Serving</title>
      <link>https://obaydakov.github.io/post/2018/mmlspark-serving/</link>
      <pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/mmlspark-serving/</guid>
      <description>An engine for deploying Spark jobs as distributed web services
 Distributed: Takes full advantage of Node, JVM, and thread level parallelism that Spark is famous for.
 Fast: No single node bottlenecks, no round trips to Python. Requests can be routed directly to and from worker JVMs through network switches. Spin up a web service in a matter of seconds.
 Deployable Anywhere: Works anywhere that runs Spark such as Databricks, HDInsight, AZTK, DSVMs, local, or on your own cluster.</description>
    </item>
    
    <item>
      <title>Spark Dataframes transformations with state Monad</title>
      <link>https://obaydakov.github.io/post/2018/spark-dataframes-transformations-with-state-monad/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/spark-dataframes-transformations-with-state-monad/</guid>
      <description>Link
Functional Data Transformations</description>
    </item>
    
    <item>
      <title>What is BigDL</title>
      <link>https://obaydakov.github.io/post/2018/what-is-bigdl/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/what-is-bigdl/</guid>
      <description>BigDL is a distributed deep learning library for Apache Spark; with BigDL, users can write their deep learning applications as standard Spark programs, which can directly run on top of existing Spark or Hadoop clusters.
Rich deep learning support. Modeled after Torch, BigDL provides comprehensive support for deep learning, including numeric computing (via Tensor) and high level neural networks; in addition, users can load pre-trained Caffe or Torch or Keras models into Spark programs using BigDL.</description>
    </item>
    
    <item>
      <title>Introducing Qubole’s Spark Tuning Tool</title>
      <link>https://obaydakov.github.io/post/2018/introducing-qubole-s-spark-tuning-tool/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/introducing-qubole-s-spark-tuning-tool/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Monitoring Apache Spark with Prometheus on Kubernetes</title>
      <link>https://obaydakov.github.io/post/2018/monitoring-apache-spark-with-prometheus-on-kubernetes/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/monitoring-apache-spark-with-prometheus-on-kubernetes/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Running Zeppelin Spark notebooks on Kubernetes</title>
      <link>https://obaydakov.github.io/post/2018/running-zeppelin-spark-notebooks-on-kubernetes/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/running-zeppelin-spark-notebooks-on-kubernetes/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Scala Machine Learning Projects, published by Packt</title>
      <link>https://obaydakov.github.io/post/2018/scala-machine-learning-projects-published-by-packt/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/scala-machine-learning-projects-published-by-packt/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Spark Memory Management</title>
      <link>https://obaydakov.github.io/post/2018/spark-memory-management/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/spark-memory-management/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Sparkling Water Pipeline Productionalization¶</title>
      <link>https://obaydakov.github.io/post/2018/sparkling-water-pipeline-productionalization/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/sparkling-water-pipeline-productionalization/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>How to setup and structure a spark application in scala</title>
      <link>https://obaydakov.github.io/post/2018/how-to-setup-and-structure-a-spark-application-in-scala/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/how-to-setup-and-structure-a-spark-application-in-scala/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Scala Machine Learning Projects</title>
      <link>https://obaydakov.github.io/post/2018/scala-machine-learning-projects/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/scala-machine-learning-projects/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Running Apache Spark on Nomad</title>
      <link>https://obaydakov.github.io/post/2018/running-apache-spark-on-nomad/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/running-apache-spark-on-nomad/</guid>
      <description>Nomad is well-suited for analytical workloads, given its performance characteristics and first-class support for batch scheduling. Apache Spark is a popular data processing engine/framework that has been architected to use third-party schedulers.
The Nomad ecosystem includes a fork of Apache Spark that natively integrates Nomad as a cluster manager and scheduler for Spark. When running on Nomad, the Spark executors that run Spark tasks for your application, and optionally the application driver itself, run as Nomad tasks in a Nomad job.</description>
    </item>
    
    <item>
      <title>Running Zeppelin Spark notebooks on Kubernetes</title>
      <link>https://obaydakov.github.io/post/2018/running-zeppelin-spark-notebooks-on-kubernetes/</link>
      <pubDate>Fri, 16 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/running-zeppelin-spark-notebooks-on-kubernetes/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>sparklyr 0.7</title>
      <link>https://obaydakov.github.io/post/2018/sparklyr-0-7/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2018/sparklyr-0-7/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Spark Streaming example</title>
      <link>https://obaydakov.github.io/post/2017/spark-streaming-example/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/spark-streaming-example/</guid>
      <description>Slides
Anthology of Technical Assets on Apache Spark’s Structured Streaming
Processing Data in Apache Kafka with Structured Streaming in Apache Spark 2.2</description>
    </item>
    
    <item>
      <title>Scla Code Exampels (Spark)</title>
      <link>https://obaydakov.github.io/post/2017/scla-code-exampels-spark/</link>
      <pubDate>Tue, 12 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/scla-code-exampels-spark/</guid>
      <description></description>
    </item>
    
    <item>
      <title>sparklyr: R interface for Apache Spark</title>
      <link>https://obaydakov.github.io/post/2017/sparklyr-r-interface-for-apache-spark/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/sparklyr-r-interface-for-apache-spark/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comparison of ML Classifiers Using Sparklyr</title>
      <link>https://obaydakov.github.io/post/2017/comparison-of-ml-classifiers-using-sparklyr/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/comparison-of-ml-classifiers-using-sparklyr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Apache Bahir</title>
      <link>https://obaydakov.github.io/post/2017/apache-bahir/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/apache-bahir/</guid>
      <description>Apache Bahir provides extensions to multiple distributed analytic platforms, extending their reach with a diversity of streaming connectors and SQL data sources.
Currently, Bahir provides extensions for Apache Spark and Apache Flink.
Link</description>
    </item>
    
    <item>
      <title>High performance spark examples</title>
      <link>https://obaydakov.github.io/post/2017/high-performance-spark-examples/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/high-performance-spark-examples/</guid>
      <description>Examples
Book</description>
    </item>
    
    <item>
      <title>Productionizing Apache SparkT MLlib Models for Real-time Prediction Serving</title>
      <link>https://obaydakov.github.io/post/2017/c-users-oleg-baydakov-documents-myblog-new-myblog-hugo/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/c-users-oleg-baydakov-documents-myblog-new-myblog-hugo/</guid>
      <description>Data science and machine learning tools traditionally focus on training models. When companies begin to employ machine learning in actual production workflows, they encounter new sources of friction such as sharing models across teams, deploying identical models on different systems, and maintaining featurization logic. In this webinar, we discuss how Databricks provides a smooth path for productionizing Apache Spark MLlib models and featurization pipelines.
Databricks Model Scoring provides a simple API for exporting MLlib models and pipelines.</description>
    </item>
    
    <item>
      <title>Data Lineage Tracking and Visualization tool for Apache Spark</title>
      <link>https://obaydakov.github.io/post/2017/data-lineage-tracking-and-visualization-tool-for-apache-spark/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/data-lineage-tracking-and-visualization-tool-for-apache-spark/</guid>
      <description>Spline (from Spark lineage) project helps people get insight into data processing performed by Apache Spark.
The project consists of two parts:
A core library that sits on drivers, capturing data lineages from the jobs being executed by analyzing Spark execution plans and a Web UI application that visualizes the stored data lineages.
Article</description>
    </item>
    
    <item>
      <title>Spark ML and Scala</title>
      <link>https://obaydakov.github.io/post/2017/spark-ml-and-scala/</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/spark-ml-and-scala/</guid>
      <description>Usefull links:
Spark MLLib - Predict Store Sales with ML Pipelines
sparktutorials.net
KeystoneML
Streamline the Machine Learning Process Using Apache Spark ML Pipelines
Spam Detection with Sparkling Water and Spark Machine Learning Pipelines
Extend Spark ML for your own model/transformer types
Spam classification using Spark&amp;rsquo;s DataFrames, ML and Zeppelin (Part 1)
How-to: Predict Telco Churn with Apache Spark MLlib
Feature Extraction and Transformation - RDD-based API
Spark Machine Learning Pipeline by Example</description>
    </item>
    
    <item>
      <title>Spark and XGBoost using Scala</title>
      <link>https://obaydakov.github.io/post/2017/spark-and-xgboost-using-scala/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/spark-and-xgboost-using-scala/</guid>
      <description>Recently XGBoost project released a package on github where it is included interface to scala, java and spark (more info at this link).
I would like to run xgboost on a big set of data.
In this post I just report the scala code lines which can be useful to run spark and xgboost.
In a further post I&amp;rsquo;m going to show the software setup and the integration of this project in Itellij IDEA community edition IDE.</description>
    </item>
    
    <item>
      <title>Spark ML</title>
      <link>https://obaydakov.github.io/post/2017/spark-ml/</link>
      <pubDate>Sun, 02 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/spark-ml/</guid>
      <description>Spark MLLib - Predict Store Sales with ML Pipelines
sparktutorials.net
KeystoneML
Streamline the Machine Learning Process Using Apache Spark ML Pipelines
Spam Detection with Sparkling Water and Spark Machine Learning Pipelines
Extend Spark ML for your own model/transformer types
Spam classification using Spark&amp;rsquo;s DataFrames, ML and Zeppelin (Part 1)
How-to: Predict Telco Churn with Apache Spark MLlib
Feature Extraction and Transformation - RDD-based API
Spark Machine Learning Pipeline by Example</description>
    </item>
    
  </channel>
</rss>