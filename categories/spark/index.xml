<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on Oleg Baydakov</title>
    <link>https://obaydakov.github.io/categories/spark/</link>
    <description>Recent content in Spark on Oleg Baydakov</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Nov 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://obaydakov.github.io/categories/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>sparklyr: R interface for Apache Spark</title>
      <link>https://obaydakov.github.io/post/2017/sparklyr-r-interface-for-apache-spark/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/sparklyr-r-interface-for-apache-spark/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comparison of ML Classifiers Using Sparklyr</title>
      <link>https://obaydakov.github.io/post/2017/comparison-of-ml-classifiers-using-sparklyr/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/comparison-of-ml-classifiers-using-sparklyr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Apache Bahir</title>
      <link>https://obaydakov.github.io/post/2017/apache-bahir/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/apache-bahir/</guid>
      <description>Apache Bahir provides extensions to multiple distributed analytic platforms, extending their reach with a diversity of streaming connectors and SQL data sources.
Currently, Bahir provides extensions for Apache Spark and Apache Flink.
Link</description>
    </item>
    
    <item>
      <title>High performance spark examples</title>
      <link>https://obaydakov.github.io/post/2017/high-performance-spark-examples/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/high-performance-spark-examples/</guid>
      <description>Examples
Book</description>
    </item>
    
    <item>
      <title>Productionizing Apache SparkT MLlib Models for Real-time Prediction Serving</title>
      <link>https://obaydakov.github.io/post/2017/c-users-oleg-baydakov-documents-myblog-new-myblog-hugo/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/c-users-oleg-baydakov-documents-myblog-new-myblog-hugo/</guid>
      <description>Data science and machine learning tools traditionally focus on training models. When companies begin to employ machine learning in actual production workflows, they encounter new sources of friction such as sharing models across teams, deploying identical models on different systems, and maintaining featurization logic. In this webinar, we discuss how Databricks provides a smooth path for productionizing Apache Spark MLlib models and featurization pipelines.
Databricks Model Scoring provides a simple API for exporting MLlib models and pipelines.</description>
    </item>
    
    <item>
      <title>Data Lineage Tracking and Visualization tool for Apache Spark</title>
      <link>https://obaydakov.github.io/post/2017/data-lineage-tracking-and-visualization-tool-for-apache-spark/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/data-lineage-tracking-and-visualization-tool-for-apache-spark/</guid>
      <description>Spline (from Spark lineage) project helps people get insight into data processing performed by Apache Spark.
The project consists of two parts:
A core library that sits on drivers, capturing data lineages from the jobs being executed by analyzing Spark execution plans and a Web UI application that visualizes the stored data lineages.
Article</description>
    </item>
    
    <item>
      <title>Spark ML and Scala</title>
      <link>https://obaydakov.github.io/post/2017/spark-ml-and-scala/</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/spark-ml-and-scala/</guid>
      <description>Usefull links:
Spark MLLib - Predict Store Sales with ML Pipelines
sparktutorials.net
KeystoneML
Streamline the Machine Learning Process Using Apache Spark ML Pipelines
Spam Detection with Sparkling Water and Spark Machine Learning Pipelines
Extend Spark ML for your own model/transformer types
Spam classification using Spark&amp;rsquo;s DataFrames, ML and Zeppelin (Part 1)
How-to: Predict Telco Churn with Apache Spark MLlib
Feature Extraction and Transformation - RDD-based API
Spark Machine Learning Pipeline by Example</description>
    </item>
    
    <item>
      <title>Spark and XGBoost using Scala</title>
      <link>https://obaydakov.github.io/post/2017/spark-and-xgboost-using-scala/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/spark-and-xgboost-using-scala/</guid>
      <description>Recently XGBoost project released a package on github where it is included interface to scala, java and spark (more info at this link).
I would like to run xgboost on a big set of data.
In this post I just report the scala code lines which can be useful to run spark and xgboost.
In a further post I&amp;rsquo;m going to show the software setup and the integration of this project in Itellij IDEA community edition IDE.</description>
    </item>
    
    <item>
      <title>Spark ML</title>
      <link>https://obaydakov.github.io/post/2017/spark-ml/</link>
      <pubDate>Sun, 02 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/spark-ml/</guid>
      <description>Spark MLLib - Predict Store Sales with ML Pipelines
sparktutorials.net
KeystoneML
Streamline the Machine Learning Process Using Apache Spark ML Pipelines
Spam Detection with Sparkling Water and Spark Machine Learning Pipelines
Extend Spark ML for your own model/transformer types
Spam classification using Spark&amp;rsquo;s DataFrames, ML and Zeppelin (Part 1)
How-to: Predict Telco Churn with Apache Spark MLlib
Feature Extraction and Transformation - RDD-based API
Spark Machine Learning Pipeline by Example</description>
    </item>
    
  </channel>
</rss>