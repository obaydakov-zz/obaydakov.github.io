<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Oleg Baydakov</title>
    <link>https://obaydakov.github.io/categories/deep-learning/</link>
    <description>Recent content in Deep Learning on Oleg Baydakov</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Dec 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://obaydakov.github.io/categories/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Having Fun with Deep Convolutional GANs</title>
      <link>https://obaydakov.github.io/post/2017/having-fun-with-deep-convolutional-gans/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/having-fun-with-deep-convolutional-gans/</guid>
      <description>Deep Learning Application Examples !!!
Deep convolutional generative adversarial networks with TensorFlow
Deep Learning with Apache MXNet</description>
    </item>
    
    <item>
      <title>OpenDataScience Machine Learning course</title>
      <link>https://obaydakov.github.io/post/2017/opendatascience-machine-learning-course/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/opendatascience-machine-learning-course/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Backpropagation Example</title>
      <link>https://obaydakov.github.io/post/2017/backpropagation-example/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/backpropagation-example/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Learning Specialization by Andrew Ng — 21 Lessons Learned</title>
      <link>https://obaydakov.github.io/post/2017/deep-learning-specialization-by-andrew-ng-21-lessons-learned/</link>
      <pubDate>Sat, 09 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/deep-learning-specialization-by-andrew-ng-21-lessons-learned/</guid>
      <description>There are currently 3 courses available in the specialization:
 Neural Networks and Deep Learning
 Improving Deep Neural Networks: Hyperparamater tuning, Regularization and Optimization
 Structuring Machine Learning Projects</description>
    </item>
    
    <item>
      <title>Convolutional Network in Python</title>
      <link>https://obaydakov.github.io/post/2017/convolutional-network-in-python/</link>
      <pubDate>Fri, 08 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/convolutional-network-in-python/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Customer Analytics: Using Deep Learning With Keras To Predict Customer Churn</title>
      <link>https://obaydakov.github.io/post/customer-analytics-using-deep-learning-with-keras-to-predict-customer-churn/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/customer-analytics-using-deep-learning-with-keras-to-predict-customer-churn/</guid>
      <description>Customer churn is a problem that all companies need to monitor, especially those that depend on subscription-based revenue streams. The simple fact is that most organizations have data that can be used to target these individuals and to understand the key drivers of churn, and we now have Keras for Deep Learning available in R (Yes, in R!!), which predicted customer churn with 82% accuracy. We’re super excited for this article because we are using the new keras package to produce an Artificial Neural Network (ANN) model on the IBM Watson Telco Customer Churn Data Set!</description>
    </item>
    
    <item>
      <title>Generative Adversarial Networks (GANs): Engine and Applications</title>
      <link>https://obaydakov.github.io/post/2017/generative-adversarial-networks-gans-engine-and-applications/</link>
      <pubDate>Sat, 16 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/generative-adversarial-networks-gans-engine-and-applications/</guid>
      <description>Generative adversarial networks (GANs) are a class of neural networks that are used in unsupervised machine learning. They help to solve such tasks as image generation from descriptions, getting high resolution images from low resolution ones, predicting which drug could treat a certain disease, retrieving images that contain a given pattern, etc.</description>
    </item>
    
    <item>
      <title>Adventures in Machine Learning New</title>
      <link>https://obaydakov.github.io/post/2017/adventures-in-machine-learning/</link>
      <pubDate>Thu, 17 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/adventures-in-machine-learning/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>ScalNet - A Scala wrapper for Deeplearning4j, inspired by Keras. Scala &#43; DL &#43; Spark &#43; GPUs</title>
      <link>https://obaydakov.github.io/post/2017/scalnet-a-scala-wrapper-for-deeplearning4j-inspired-by-keras-scala-dl-spark-gpus/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/scalnet-a-scala-wrapper-for-deeplearning4j-inspired-by-keras-scala-dl-spark-gpus/</guid>
      <description>ScalNet is a wrapper around Deeplearning4j emulating a Keras like API for deep learning. ScalNet is released under an Apache 2.0 license. By contributing code to this repository, you agree to make your contribution available under an Apache 2.0 license.
Link</description>
    </item>
    
    <item>
      <title>Deep Learning Model Zoo</title>
      <link>https://obaydakov.github.io/post/2017/deep-learning-model-zoo/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/deep-learning-model-zoo/</guid>
      <description>A collection of standalone TensorFlow models in Jupyter Notebooks
Link
Free Chapters from Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python</description>
    </item>
    
    <item>
      <title>Deep Learning Limitations</title>
      <link>https://obaydakov.github.io/post/2017/deep-learning-limitations/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/deep-learning-limitations/</guid>
      <description>Limitations of deep learning and future</description>
    </item>
    
    <item>
      <title>CatBoost</title>
      <link>https://obaydakov.github.io/post/2017/catboost/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/catboost/</guid>
      <description>CatBoost is a state-of-the-art open-source gradient boosting on decision trees library.
Developed by Yandex researchers and engineers, it is the successor of the MatrixNet algorithm that is widely used within the company for ranking tasks, forecasting and making recommendations. It is universal and can be applied across a wide range of areas and to a variety of problems.
Accurate: leads or ties competition on standard benchmarks Robust: reduces the need for extensive hyper-parameter tuning Easy-to-use: offers Python interfaces integrated with scikit, as well as R and command-line interfaces Practical: uses categorical features directly and scalably Extensible: allows specifying custom loss functions</description>
    </item>
    
    <item>
      <title>Deep Learning and NLP</title>
      <link>https://obaydakov.github.io/post/2017/deep-learning-and-nlp/</link>
      <pubDate>Thu, 06 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/deep-learning-and-nlp/</guid>
      <description>Link A news-analysis NeuralNet learns from a language NeuralNet</description>
    </item>
    
    <item>
      <title>Comprehensive list of activation functions in neural networks with pros/cons</title>
      <link>https://obaydakov.github.io/post/2017/comprehensive-list-of-activation-functions-in-neural-networks-with-pros-cons/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/comprehensive-list-of-activation-functions-in-neural-networks-with-pros-cons/</guid>
      <description>Link</description>
    </item>
    
    <item>
      <title>Convolutional Neural Network</title>
      <link>https://obaydakov.github.io/post/2017/convolutional-neural-network/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/convolutional-neural-network/</guid>
      <description>How to make a Convolutional Neural Network in TensorFlow for recognizing handwritten digits from the MNIST data-set. Video Tutorial</description>
    </item>
    
    <item>
      <title>Practical Recommendations for Gradient-Based Training of Deep Architectures</title>
      <link>https://obaydakov.github.io/post/2017/practical-recommendations-for-gradient-based-training-of-deep-architectures/</link>
      <pubDate>Wed, 03 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/practical-recommendations-for-gradient-based-training-of-deep-architectures/</guid>
      <description>Abstract Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles, called hyperparameters. This chapter is meant as a practical guide with recommendations for some of the most commonly used hyper-parameters, in particular in the context of learning algorithms based on backpropagated gradient and gradient-based optimization. It also discusses how to deal with the fact that more interesting results can be obtained when allowing one to adjust many hyper-parameters.</description>
    </item>
    
    <item>
      <title>Examples of using DL4J on Spark and Scala</title>
      <link>https://obaydakov.github.io/post/2017/examples-of-using-dl4j-on-spark-and-scala/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/examples-of-using-dl4j-on-spark-and-scala/</guid>
      <description>Examples: Project for the talk on NLP using LSTM implementation from DL4J on Spark
Deeplearning4J Examples for Scala
Exploring convolutional neural networks with DL4J
ND4S is open-source Scala bindings for ND4J</description>
    </item>
    
    <item>
      <title>Using TensorFlow with R</title>
      <link>https://obaydakov.github.io/post/2017/using-tensorflow-with-r/</link>
      <pubDate>Sun, 02 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://obaydakov.github.io/post/2017/using-tensorflow-with-r/</guid>
      <description>TensorFlowT is an open source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API. TensorFlow was originally developed by researchers and engineers working on the Google Brain Team within Google&amp;rsquo;s Machine Intelligence research organization for the purposes of conducting machine learning and deep neural networks research, but the system is general enough to be applicable in a wide variety of other domains as well.</description>
    </item>
    
  </channel>
</rss>